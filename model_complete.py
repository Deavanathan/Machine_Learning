# -*- coding: utf-8 -*-
"""model_complete.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1InsCaiy0Vn84r3UcSyWzHRegCL6MPRgB
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.figure as fgr
from matplotlib.pyplot import figure
import seaborn as sns
import pylab
import plotly.express as px

from scipy.stats import skew
import statsmodels.api as sm
import statsmodels.formula.api as smf
from sklearn.feature_selection import VarianceThreshold
from sklearn.preprocessing import MinMaxScaler,StandardScaler,RobustScaler,MaxAbsScaler,LabelEncoder,OneHotEncoder,PowerTransformer
from sklearn.metrics import mean_squared_error,accuracy_score,recall_score,precision_score,f1_score,roc_auc_score
from sklearn.model_selection import train_test_split,RepeatedKFold,KFold,cross_val_score,GridSearchCV,RandomizedSearchCV,RepeatedStratifiedKFold,StratifiedKFold
from sklearn.metrics import make_scorer,classification_report,confusion_matrix,ConfusionMatrixDisplay, roc_curve, roc_auc_score

!pip install plotly

from sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier , GradientBoostingClassifier, VotingClassifier, BaggingClassifier , ExtraTreesClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

!pip install catboost

data = pd.read_csv('/content/trained_data.xls')

data = pd.DataFrame(data)

data.head()

#data.info()

def grab_col_names(d, cat_th=10, car_th=20):
    # Categorical columns (with object type)
    cat_cols = [col for col in d.columns if d[col].dtypes == "O"]

    # Numerical but considered categorical due to low cardinality
    num_but_cat = [col for col in d.columns if d[col].nunique() < cat_th and d[col].dtypes != "O"]


    cat_but_car = [col for col in d.columns if d[col].nunique() > car_th and d[col].dtypes == "O"]

    cat_cols = cat_cols + num_but_cat


    cat_cols = [col for col in cat_cols if col not in cat_but_car]


    num_cols = [col for col in d.columns if d[col].dtypes != "O"]
    num_cols = [col for col in num_cols if col not in num_but_cat]


    print(f"Observations: {d.shape[0]}")
    print(f"Variables: {d.shape[1]}")
    print(f'Categorical columns (cat_cols): {len(cat_cols)}')
    print(f'Numerical columns (num_cols): {len(num_cols)}')
    print(f'Categorical but cardinal columns (cat_but_car): {len(cat_but_car)}')
    print(f'Numerical but categorical columns (num_but_cat): {len(num_but_cat)}')

    return cat_cols, num_cols, cat_but_car

cat_cols, num_cols, cat_but_car = grab_col_names(data)

cat_cols, num_cols, cat_but_car

for i in cat_cols:
  print(i , data[i].unique())

for i in data.columns:
  print(i,data[i].isnull().sum())

def cat_summary(d, col_name, plot=False):
    # Check if the column exists in the DataFrame
    if col_name not in d.columns:
        print(f"Column '{col_name}' does not exist in the DataFrame.")
        return

    # Show a summary only for categorical columns (discrete values)
    unique_values = d[col_name].nunique()
    if unique_values > 20:  # Skip columns with more than 20 unique values
        print(f"Skipping {col_name} as it has too many unique values ({unique_values}).")
        return

    # Create DataFrame with value counts and ratios
    summary_df = pd.DataFrame({col_name: d[col_name].value_counts(),
                               "Ratio (%)": (100 * d[col_name].value_counts() / len(d)).round(2)})

    print(f"Summary for '{col_name}':")
    print(summary_df)
    print("#" * 120)

    if plot:
        # Set the style for plots
        sns.set(style="whitegrid")

        # Create subplots for count plot and pie chart
        fig, axs = plt.subplots(1, 2, figsize=(14, 6), gridspec_kw={'width_ratios': [2, 1]})

        # Countplot with a color palette
        sns.countplot(x=d[col_name], ax=axs[0], palette='Set2')
        axs[0].set_title(f'Frequency of {col_name}', fontsize=14)
        axs[0].tick_params(axis='x', rotation=90)
        axs[0].set_xlabel(col_name, fontsize=12)
        axs[0].set_ylabel('Count', fontsize=12)

        # Pie chart for percentage distribution
        values = d[col_name].value_counts()
        colors = sns.color_palette('Set3', len(values))
        wedges, texts, autotexts = axs[1].pie(values, labels=values.index, autopct='%1.1f%%',
                                              colors=colors, startangle=90, textprops=dict(color="w"))
        axs[1].set_title(f'{col_name} Distribution', fontsize=14)

        # Improve legend format for pie chart
        plt.legend(wedges, [f'{label} ({count})' for label, count in zip(values.index, values)],
                   title=col_name, loc='center left', bbox_to_anchor=(1, 0, 0.5, 1))

        # Add annotations to the pie chart for more clarity
        for text in autotexts:
            text.set_size(10)
            text.set_weight('bold')

        plt.tight_layout()
        plt.show()

# Specify categorical columns manually from the dataset
# cat_cols = ['Protocol', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Label', 'SYN Flag Count',
#             'ACK Flag Count', 'RST Flag Count']  # Add any other columns that are categorical

# Loop through categorical columns and generate summary and plots
for col in cat_cols:
    cat_summary(data, col, plot=True)

print(data.columns)

"""### Numerical columns"""

# # Distribution Plots:
# def my_histplot(df, col, ax):
#     sns.histplot(df[col], kde=True, ax=ax)
#     ax.set_title(f'Histogram Plot of {col}')
# def my_distplot(df,col, ax):
#     sns.histplot(df[col], ax=ax, kde=True)

#     ax.set_title(f'Distribution Plot of {col}')
# def my_kdeplot(df, col, ax):
#     sns.kdeplot(df[col], ax=ax, fill=True)
#     ax.set_title(f'KDE Plot of {col}')

# # Relational Plots:
# def my_scatterplot(df, col, ax):
#     sns.scatterplot(df[col], ax=ax)
#     ax.set_title(f'Scatter Plot of {col}')
# def my_lineplot(df, col, ax):
#     sns.lineplot(df[col], ax=ax)
#     ax.set_title(f'Line Plot of {col}')

# # Categorical Plots:
# def my_pie_chart(df, col, ax):
#     labels = df[col].value_counts()
#     ax.pie(labels, labels=labels.index, autopct='%1.1f%%')
#     ax.set_title(f'Pie Chart of {col}')
# def my_countplot(df, col, ax):
#     sns.countplot(x=df[col], ax=ax)
#     ax.set_title(f'Count Plot of {col}')
#     ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
# def my_boxplot(df, col, ax):
#     sns.boxplot(y=df[col], ax=ax)
# def my_violinplot(df, col, ax):
#     sns.violinplot(y=df[col], ax=ax)

# # Matrix Plots:
# def my_heatmap(df, size):
#     if size: plt.figure(figsize=size)
#     sns.heatmap(df.corr(), annot=True, fmt=".1f", cmap='Blues', annot_kws={"size": 12})
#     plt.title('Correlation Heatmap')
#     plt.show()

# #vsplot
# def my_vsplot(df, normal_col, label_col):
#     plt.figure(figsize=(10, 6), dpi=80)
#     plt.bar(list(dict(df[normal_col].value_counts()).keys()), dict(df[normal_col].value_counts()).values(), color='r')
#     plt.bar(list(dict(df[normal_col][df[label_col] == 1].value_counts()).keys()), dict(df[normal_col][df[label_col] == 1].value_counts()).values(), color='b')

#     plt.xlabel(normal_col)
#     plt.ylabel('Count')
#     plt.legend(['All', label_col])
#     # plt.title('The number of requests from different protocols')

# def plot_charts_grid_single_feature(df, plot_func, size=(12, 4), n_col=1):
#     if len(df.columns) == 0:
#         return
#     n_rows = (len(df.columns) + n_col-1) // n_col
#     fig, axes = plt.subplots(n_rows, n_col, figsize=(size[0]*n_col, size[1]*n_rows))
#     if len(df.columns) == 1:
#         axes = np.array([axes])
#     axes = axes.flatten()

#     for i, label in enumerate(df.columns):
#         plot_func(df, label, axes[i])
#         axes[i].set_xlabel(label)

#     for j in range(i+1, n_rows*n_col):
#         axes[j].axis('off')

#     plt.tight_layout()
#     plt.show()

# Function to customize plots
def customize_plot(ax, title, xlabel=None, ylabel=None):
    ax.set_title(title, fontsize=14)
    if xlabel:
        ax.set_xlabel(xlabel)
    if ylabel:
        ax.set_ylabel(ylabel)

# Enhanced Histogram Plot
def my_histplot(df, col, ax, bins=30):
    sns.histplot(df[col], kde=True, bins=bins, ax=ax, color='darkblue')
    ax.set_title(f'Advanced Histogram Plot of {col}', fontsize=14)

# Enhanced KDE Plot
def my_kdeplot(df, col, ax, shade=True):
    sns.kdeplot(df[col], ax=ax, fill=shade, color='green', linewidth=2)
    ax.set_title(f'Advanced KDE Plot of {col}', fontsize=14)

# Interactive Scatter Plot using Plotly
def my_scatterplot(df, col, label_col):
    fig = px.scatter(df, x=df.index, y=col, color=label_col, title=f'Interactive Scatter Plot of {col}')
    fig.show()

# Enhanced Line Plot
def my_lineplot(df, col, ax):
    sns.lineplot(x=df.index, y=col, data=df, ax=ax, color='orange', lw=2)
    ax.set_title(f'Advanced Line Plot of {col}', fontsize=14)

# Enhanced Pie Chart
def my_pie_chart(df, col, ax):
    labels = df[col].value_counts()
    ax.pie(labels, labels=labels.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette("Set2"))
    ax.set_title(f'Pie Chart of {col}', fontsize=14)

# Enhanced Count Plot
def my_countplot(df, col, ax):
    sns.countplot(x=df[col], ax=ax, palette="Set3")
    ax.set_title(f'Count Plot of {col}', fontsize=14)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=10)

# Enhanced Heatmap
def my_heatmap(df, size=(10, 8)):
    plt.figure(figsize=size)
    corr = df.corr().round(2)
    sns.heatmap(corr, annot=True, fmt=".2f", cmap='coolwarm', annot_kws={"size": 10}, cbar=True)
    plt.title('Correlation Heatmap', fontsize=16)
    plt.tight_layout()
    plt.show()

# Enhanced vsplot
def my_vsplot(df, normal_col, label_col):
    plt.figure(figsize=(12, 6), dpi=100)
    all_values = dict(df[normal_col].value_counts())
    labeled_values = dict(df[normal_col][df[label_col] == 1].value_counts())

    labels = list(all_values.keys())
    all_heights = all_values.values()
    labeled_heights = [labeled_values.get(key, 0) for key in labels]

    plt.bar(labels, all_heights, color='red', alpha=0.7, label='All')
    plt.bar(labels, labeled_heights, color='blue', alpha=0.7, label=label_col)
    plt.xticks(rotation=90)
    plt.legend()
    plt.xlabel(normal_col)
    plt.ylabel('Count')
    plt.title(f'Comparison Plot of {normal_col} vs {label_col}')
    plt.tight_layout()
    plt.show()

# Function to plot multiple charts in a grid
def plot_charts_grid_single_feature(df, plot_func, size=(12, 4), n_col=2):
    cols = df.columns if len(df.columns) > 1 else [df.columns[0]]
    n_rows = (len(cols) + n_col - 1) // n_col

    fig, axes = plt.subplots(n_rows, n_col, figsize=(size[0] * n_col, size[1] * n_rows))
    axes = np.array(axes).flatten() if n_rows * n_col > 1 else [axes]

    for i, col in enumerate(cols):
        plot_func(df, col, axes[i])
        axes[i].set_xlabel(col)

    for j in range(i + 1, len(axes)):
        axes[j].axis('off')

    plt.tight_layout()
    plt.show()

plot_charts_grid_single_feature(data[num_cols], my_histplot)

#Box Plot

plt.figure(figsize=(12,6))
sns.boxplot(x='Label',y='Flow Duration' , data=data)
plt.title('Flow Duration Distrubution for DDoS vs Normal Traffic')
plt.show()

# Automatically create a custom palette for all labels in the 'Label' column
unique_labels = data['Label'].unique()  # Get unique values in the 'Label' column
custom_palette = sns.color_palette("Set2", len(unique_labels))  # Generate a palette with enough colors
label_palette = dict(zip(unique_labels, custom_palette))  # Map unique labels to the colors

# Enhanced Boxplot for Packet Length Mean Distribution
plt.figure(figsize=(14, 7))

# Drawing the boxplot with the updated palette
sns.boxplot(x='Protocol', y='Packet Length Mean', hue='Label', data=data, palette=label_palette)

# Adding title and axis labels with customization
plt.title('Packet Length Mean Distribution: DDoS vs Normal Traffic', fontsize=16, fontweight='bold')
plt.xlabel('Protocol', fontsize=12)
plt.ylabel('Packet Length Mean', fontsize=12)

# Rotating x-axis labels for better readability
plt.xticks(rotation=45, fontsize=10)

# Improving legend placement outside the plot for clarity
plt.legend(title='Traffic Label', bbox_to_anchor=(1.05, 1), loc='upper left')

# Displaying the plot
plt.tight_layout()
plt.show()

flag_columns = ['SYN Flag Count','ACK Flag Count','FIN Flag Count', 'RST Flag Count']

for flag in flag_columns:
  plt.figure(figsize=(10,6))
  sns.countplot(x=flag , hue = 'Label' , data=data)
  plt.title(f'{flag} Distribution by Attack Label')
  plt.show()

# Setting up the figure
plt.figure(figsize=(10, 6), dpi=80)

# Counting the occurrences of each protocol
protocol_counts = data['Protocol'].value_counts()  # Count of all protocols
malicious_protocol_counts = data[data['Label'] == 'DDoS']['Protocol'].value_counts()  # Count of malicious protocols

# Getting keys (protocols) and corresponding counts
protocols = protocol_counts.index.tolist()  # List of protocol names
all_counts = protocol_counts.values.tolist()  # List of total counts
malicious_counts = [malicious_protocol_counts.get(protocol, 0) for protocol in protocols]  # Malicious counts

# Creating bar width and positions
bar_width = 0.4
r1 = range(len(all_counts))  # Position of bars for "All"
r2 = [x + bar_width for x in r1]  # Position of bars for "Malicious"

# Plotting both bar charts
plt.bar(r1, all_counts, color='blue', width=bar_width, edgecolor='grey', label='All')
plt.bar(r2, malicious_counts, color='red', width=bar_width, edgecolor='grey', label='Malicious')

# Customizing the plot
plt.xlabel('Protocol', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.xticks([r + bar_width / 2 for r in range(len(all_counts))], protocols, rotation=45)  # Rotate x-axis labels
plt.title('The Number of Requests Generated from Different Protocols', fontsize=14, fontweight='bold')

# Adding a legend
plt.legend(title='Traffic Type')

# Display the plot
plt.tight_layout()
plt.show()

sns.pairplot(data[['Flow Duration', 'Flow Packets/s', 'Flow Bytes/s', 'Label']], hue='Label', palette='Set1')
plt.show()

#BoxPlot For Flow Packets
plt.figure(figsize=(12,6))
sns.boxplot(x='Label',y='Flow Packets/s' , data=data)
plt.title('Flow Packets per Second by Attack Label')
plt.show()

num_cols = len(data.select_dtypes(include=[np.number]).columns) // 3 * 2

# Calculate correlation matrix
corr_matrix = data.select_dtypes(include=[np.number]).corr()

# Plot heatmap using seaborn
plt.figure(figsize=(num_cols+1, num_cols+1))  # Adjust figure size based on num_cols
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm")

# Show plot
plt.show()

numeric_data = data.select_dtypes(include=[np.number])

# Apply VarianceThreshold to remove low variance columns
selector = VarianceThreshold(threshold=0.01)
selector.fit(numeric_data)

# Get columns that are not removed by the variance threshold
low_variance_cols = numeric_data.columns[~selector.get_support()]

low_variance_cols

remove_cols = ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'FIN Flag Count', 'Fwd Avg Bytes/Bulk',
'Fwd Avg Packets/Bulk',
'Fwd Avg Bulk Rate',
'Bwd Avg Bytes/Bulk',
'Bwd Avg Packets/Bulk',
'Bwd Avg Bulk Rate', 'ECE Flag Count', 'PSH Flag Count']

data.drop(remove_cols,axis=1,inplace=True)

data.columns

numerical_cols = data.select_dtypes(include=[np.number])

corr_matrix = numerical_cols.corr().abs()
mask = np.triu(np.ones(corr_matrix.shape),k=1)==1
upper_tri = corr_matrix.where(mask)

to_drop = [col for col in upper_tri.columns if any(upper_tri[col] > 0.8)]

print(to_drop)

len(to_drop)

remove_col1 = ['Bwd Packets Length Total',
 'Fwd Packet Length Mean',
 'Bwd Packet Length Mean',
 'Bwd Packet Length Std',
 'Flow IAT Std',
 'Flow IAT Max',
 'Fwd IAT Total',
 'Fwd IAT Mean',
 'Fwd IAT Std',
 'Fwd IAT Max',
 'Fwd IAT Min',
 'Bwd IAT Std',
 'Bwd IAT Max',
 'Fwd Packets/s',
 'Packet Length Min',
 'Packet Length Max',
 'Packet Length Mean',
 'Packet Length Std',
 'Packet Length Variance',
 'RST Flag Count',
 'Avg Packet Size',
 'Avg Fwd Segment Size',
 'Avg Bwd Segment Size',
 'Subflow Fwd Packets',
 'Subflow Fwd Bytes',
 'Subflow Bwd Packets',
 'Subflow Bwd Bytes',
 'Fwd Act Data Packets',
 'Fwd Seg Size Min',
 'Active Max',
 'Active Min',
 'Idle Mean',
 'Idle Max',
 'Idle Min']

len(remove_col1)

missing_elements = [item for item in remove_col1 if item not in to_drop]
missing_elements

data.drop(to_drop,axis=1,inplace=True)

n_numeric_cols = len(data.select_dtypes(include=[np.number]).columns) // 3 * 2
my_heatmap(data.select_dtypes(include=[np.number]), size=(n_numeric_cols+1, n_numeric_cols+1))

data['Label'].unique()

data= pd.get_dummies(data,columns=['Label'],prefix='Label')

data.head(10)

!pip install optuna

import optuna
from optuna.pruners import MedianPruner

y = data[['Label_Benign', 'Label_LDAP', 'Label_MSSQL', 'Label_NetBIOS', 'Label_Portmap', 'Label_Syn', 'Label_UDP', 'Label_UDPLag']].idxmax(axis=1)

# Now define X
X = data.drop(columns=['Label_Benign', 'Label_LDAP', 'Label_MSSQL', 'Label_NetBIOS', 'Label_Portmap', 'Label_Syn', 'Label_UDP', 'Label_UDPLag'])

# Check the shapes
print(X.shape, y.shape)

pip install --upgrade xgboost

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the objective function for Random Forest optimization
def objective_rf(trial):
    n_estimators = trial.suggest_int('n_estimators', 100, 1000)
    max_depth = trial.suggest_int('max_depth', 5, 30)
    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)
    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)

    # Create the Random Forest model with suggested hyperparameters
    model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        random_state=42
    )

    # Fit the model
    model.fit(X_train, y_train)

    # Predict on the test set
    y_pred = model.predict(X_test)

    # Calculate the f1 score (or any other evaluation metric)
    return f1_score(y_test, y_pred, average='weighted')

# Create a study with MedianPruner for early stopping
pruner = MedianPruner(n_warmup_steps=10)  # Set warmup steps before starting early stopping
rf_study = optuna.create_study(direction='maximize', pruner=pruner)

# Optimize the study with a specified number of trials and early stopping
print("Optimizing Random Forest with early stopping...")
rf_study.optimize(objective_rf, n_trials=100)

# Print the best parameters
print("Best parameters for Random Forest:", rf_study.best_params)

import xgboost as xgb
import lightgbm as lgb

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y_train.values.ravel())  # Encode y_train

# Encode y_test using the same encoder
y_test_encoded = label_encoder.transform(y_test.values.ravel())  # Encode y_test

# Define the objective function for XGBoost optimization
def objective_xgb(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
        'max_depth': trial.suggest_int('max_depth', 3, 30),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'random_state': 42
    }

    model = xgb.XGBClassifier(**params)

    # Fit the model using the encoded labels
    model.fit(X_train, y_encoded)

    # Predict on the test set
    y_pred = model.predict(X_test)

    # Calculate and return the f1 score
    return f1_score(y_test_encoded, y_pred, average='weighted')  # Use encoded y_test

# Create a study for XGBoost optimization
xgb_study = optuna.create_study(direction='maximize')

# Optimize the study
print("Optimizing XGBoost...")
xgb_study.optimize(objective_xgb, n_trials=100)

# Print the best parameters for XGBoost
print("Best parameters for XGBoost:", xgb_study.best_params)

def objective_lgb(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
        'max_depth': trial.suggest_int('max_depth', 3, 30),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'num_leaves': trial.suggest_int('num_leaves', 31, 512),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0)
    }

    model = LGBMClassifier(**params, random_state=42)

    # Use evals instead of eval_set
    model.fit(X_train, y_train,
              eval_set=[(X_test, y_test)],
              eval_metric='f1',
              verbose=False,
              early_stopping_rounds=10)

    y_pred = model.predict(X_test)
    return f1_score(y_test, y_pred, average='weighted')

lgb_study = optuna.create_study(direction='maximize', pruner=MedianPruner(n_warmup_steps=10))

# Optimize the study
print("Optimizing LightGBM with early stopping...")
lgb_study.optimize(objective_lgb, n_trials=100)

# Print the best parameters for LightGBM
print("Best parameters for LightGBM:", lgb_study.best_params)

selector = VarianceThreshold(threshold=0.01)
X_train_reduced = selector.fit_transform(X_train)
X_test_reduced = selector.transform(X_test)

# Define the objective function for LightGBM optimization
def objective_lgb(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 500),  # Reduced range for quicker optimization
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),
        'num_leaves': trial.suggest_int('num_leaves', 31, 128),  # Reduced number of leaves for speed
        'subsample': trial.suggest_float('subsample', 0.7, 1.0),  # Adjusted range for quicker convergence
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),
        'random_state': 42,
        'objective': 'multiclass',  # Set objective for multiclass
        'num_class': len(set(y_train))  # Set the number of classes
    }

    model = lgb.LGBMClassifier(**params)

    # Fit the model using y_train and the reduced features
    model.fit(X_train_reduced, y_train, eval_set=[(X_test_reduced, y_test)], eval_metric='multi_logloss')

    # Predict on the test set
    y_pred = model.predict(X_test_reduced)
    return f1_score(y_test, y_pred, average='weighted')

# Create a study for LightGBM optimization with MedianPruner
lgb_study = optuna.create_study(direction='maximize', pruner=MedianPruner(n_warmup_steps=10))

# Optimize the study
print("Optimizing LightGBM...")
lgb_study.optimize(objective_lgb, n_trials=50)  # Reduced trials for quicker completion

# Print the best parameters for LightGBM
print("Best parameters for LightGBM:", lgb_study.best_params)

# Check best parameters if optimization was successful before stopping
print("Best parameters for LightGBM:", lgb_study.best_params)

# PARAMETER CHOOSING FOR CATBOOST
def objective_catboost(trial):
    params = {
        'iterations': trial.suggest_int('iterations', 100, 1000),
        'depth': trial.suggest_int('depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0),
        'border_count': trial.suggest_int('border_count', 32, 255),
        'random_state': 42
    }

    model = CatBoostClassifier(**params, verbose=0)
    model.fit(X_train, y_train)

    # Predict on the test set
    y_pred = model.predict(X_test)
    return f1_score(y_test, y_pred, average='weighted')

# Create a study for CatBoost optimization
catboost_study = optuna.create_study(direction='maximize')

# Optimize the study
print("Optimizing CatBoost...")
catboost_study.optimize(objective_catboost, n_trials=50)  # You can adjust the number of trials

# Print the best parameters for CatBoost
print("Best parameters for CatBoost:", catboost_study.best_params)

def objective_gb(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 300),  # Reduced range
        'max_depth': trial.suggest_int('max_depth', 3, 10),  # Reduced depth range
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),  # Reduced learning rate range
        'subsample': trial.suggest_float('subsample', 0.6, 0.8)  # Adjusted range
    }

    model = GradientBoostingClassifier(**params, random_state=42)
    model.fit(X_train, y_train)

    # Evaluate
    y_pred = model.predict(X_test)
    return f1_score(y_test, y_pred, average='weighted')

# Create a study for Gradient Boosting optimization
gb_study = optuna.create_study(direction='maximize')

# Optimize the study with fewer trials
print("Optimizing Gradient Boosting Classifier...")
gb_study.optimize(objective_gb, n_trials=10)  # Fewer trials for quicker completion

# Print the best parameters for Gradient Boosting Classifier
print("Best parameters for Gradient Boosting Classifier:", gb_study.best_params)

# [W 2024-10-02 13:19:02,473] Trial 0 failed with parameters: {'n_estimators': 205, 'max_depth': 4, 'learning_rate': 0.08139625863797068, 'subsample': 0.9411992634411162}

#MODEL BUILDING FOR RANDOM FOREST
best_params = {
    'n_estimators': 276,
    'max_depth': 15,
    'min_samples_split': 4,
    'min_samples_leaf': 1,
    'random_state': 42  # Ensure reproducibility
}

# Create and train the Random Forest model
rf_model = RandomForestClassifier(**best_params)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred = rf_model.predict(X_test)

# Evaluate the model
f1 = f1_score(y_test, y_pred, average='weighted')
print(f"F1 Score for Random Forest: {f1:.4f}")

#MODEL BUILDING FOR XGBOOST
label_encoder = LabelEncoder()

# Fit the label encoder on y_train and transform both y_train and y_test
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Best parameters from the optimization
best_params_xgb = {
    'n_estimators': 126,
    'max_depth': 13,
    'learning_rate': 0.1268,
    'subsample': 0.9018,
    'colsample_bytree': 0.7163,
    'random_state': 42  # Ensure reproducibility
}

# Create and train the XGBoost model
xgb_model = xgb.XGBClassifier(**best_params_xgb)
xgb_model.fit(X_train, y_train_encoded)

# Make predictions
y_pred_xgb = xgb_model.predict(X_test)

# Evaluate the model
f1_xgb = f1_score(y_test_encoded, y_pred_xgb, average='weighted')
print(f"F1 Score for XGBoost: {f1_xgb:.4f}")

#BUILDING THE CATBOOST MODEL WITH PARAMETERS
X.columns = X.columns.str.replace(" ", "_", regex=False)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check if the features in both sets are the same
print("Training Features:", X_train.columns.tolist())
print("Test Features:", X_test.columns.tolist())

# Define the model with your best parameters
best_params = {
    'iterations': 520,
    'depth': 6,
    'learning_rate': 0.1090,
    'l2_leaf_reg': 2.7908,
    'border_count': 213
}

# Create and train the CatBoost model
final_model = CatBoostClassifier(**best_params, verbose=0)
final_model.fit(X_train, y_train)

# Evaluate the final model
y_pred_final = final_model.predict(X_test)
final_f1_score = f1_score(y_test, y_pred_final, average='weighted')
print(f"Final F1 Score on Test Set: {final_f1_score:.4f}")

# GRADIENT BOOST MODEL
best_params = {
    'n_estimators': 184,
    'max_depth': 5,
    'learning_rate': 0.0333,
    'subsample': 0.7746,
    'random_state': 42
}

# Train the Gradient Boosting model with the best parameters
model = GradientBoostingClassifier(**best_params)
model.fit(X_train, y_train)

# Evaluate the model on the test set
y_pred = model.predict(X_test)
f1 = f1_score(y_test, y_pred, average='weighted')

print("F1 Score with best parameters:", f1)

import joblib

# Save the models
joblib.dump(model, 'gradient_boosting_model.pkl')
joblib.dump(final_model, 'catboost_model.pkl')
joblib.dump(xgb_model, 'xgboost_model.pkl')
joblib.dump(rf_model, 'random_forest_model.pkl')

from google.colab import files

# Download the models
files.download('gradient_boosting_model.pkl')
files.download('catboost_model.pkl')
files.download('xgboost_model.pkl')
files.download('random_forest_model.pkl')

from sklearn.ensemble import VotingClassifier

# Create the ensemble model
ensemble_model = VotingClassifier(
    estimators=[
        ('gb', model),
        ('cat', final_model),
        ('xgb', xgb_model),
        ('rf', rf_model)
    ],
    voting='soft'  # or 'hard' based on your requirement
)

# Fit the ensemble model
ensemble_model.fit(X_train, y_train)

# Make predictions
y_pred_ensemble = ensemble_model.predict(X_test)

f1_ensemble = f1_score(y_test, y_pred_ensemble, average='weighted')
print(f"F1 Score for Ensemble Model: {f1_ensemble:.4f}")

# Calculate Recall
recall_ensemble = recall_score(y_test, y_pred_ensemble, average='weighted')
print(f"Recall for Ensemble Model: {recall_ensemble:.4f}")

joblib.dump(ensemble_model, 'ensemble_model.pkl')

# Download the ensemble model
files.download('ensemble_model.pkl')

