{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d1916f8-5659-46e2-976e-9fd07a0932c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44cd4c1e-c43e-4c86-9ca6-7959218372c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped 2248.2004-09-23.GP.spam.txt\n",
      "skipped 2526.2004-10-17.GP.spam.txt\n",
      "skipped 2698.2004-10-31.GP.spam.txt\n",
      "skipped 4566.2005-05-24.GP.spam.txt\n"
     ]
    }
   ],
   "source": [
    "def read_spam():\n",
    "    category = 'spam'\n",
    "    directory = r\"D:\\Email_Classification\\enron1\\enron1\\spam\"\n",
    "    return read_category(category , directory)\n",
    "\n",
    "\n",
    "def read_ham():\n",
    "    category = 'ham'\n",
    "    directory = r\"D:\\Email_Classification\\enron1\\enron1\\ham\"\n",
    "    return read_category(category , directory)\n",
    "\n",
    "\n",
    "def read_category(category,directory):\n",
    "    emails = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            continue\n",
    "        with open(os.path.join(directory,filename),'r') as fp:\n",
    "            try:\n",
    "                content = fp.read()\n",
    "                emails.append({'name' : filename , 'content':content, 'category' : category})\n",
    "            except:\n",
    "                print(f'skipped {filename}')\n",
    "    return emails\n",
    "\n",
    "ham = read_ham()\n",
    "spam = read_spam()\n",
    "\n",
    "ham_df = pd.DataFrame.from_records(ham)\n",
    "spam_df = pd.DataFrame.from_records(spam)\n",
    "\n",
    "df = pd.concat([ham_df, spam_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80596e17-a8b9-4394-9c94-fc0fb591a527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DEAVANATHAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DEAVANATHAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cba7e6d-3869-4559-9869-7050fdc5d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(e):\n",
    "    e = re.sub(r'<.*?>','',e)\n",
    "    e = re.sub(r'[^a-zA-Z\\s]','',e)\n",
    "    e = e.lower()\n",
    "    words = word_tokenize(e)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['clean_content'] = df['content'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49d42507-ea5c-424a-8430-85404ca195e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001.1999-12-10.farmer.ham.txt</td>\n",
       "      <td>Subject: christmas tree farm pictures\\n</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject christmas tree farm pictures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002.1999-12-13.farmer.ham.txt</td>\n",
       "      <td>Subject: vastar resources , inc .\\ngary , prod...</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject vastar resources inc gary production h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003.1999-12-14.farmer.ham.txt</td>\n",
       "      <td>Subject: calpine daily gas nomination\\n- calpi...</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject calpine daily gas nomination calpine d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004.1999-12-14.farmer.ham.txt</td>\n",
       "      <td>Subject: re : issue\\nfyi - see note below - al...</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject issue fyi see note already done stella...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005.1999-12-14.farmer.ham.txt</td>\n",
       "      <td>Subject: meter 7268 nov allocation\\nfyi .\\n- -...</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject meter nov allocation fyi forwarded lau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name  \\\n",
       "0  0001.1999-12-10.farmer.ham.txt   \n",
       "1  0002.1999-12-13.farmer.ham.txt   \n",
       "2  0003.1999-12-14.farmer.ham.txt   \n",
       "3  0004.1999-12-14.farmer.ham.txt   \n",
       "4  0005.1999-12-14.farmer.ham.txt   \n",
       "\n",
       "                                             content category  \\\n",
       "0            Subject: christmas tree farm pictures\\n      ham   \n",
       "1  Subject: vastar resources , inc .\\ngary , prod...      ham   \n",
       "2  Subject: calpine daily gas nomination\\n- calpi...      ham   \n",
       "3  Subject: re : issue\\nfyi - see note below - al...      ham   \n",
       "4  Subject: meter 7268 nov allocation\\nfyi .\\n- -...      ham   \n",
       "\n",
       "                                       clean_content  \n",
       "0               subject christmas tree farm pictures  \n",
       "1  subject vastar resources inc gary production h...  \n",
       "2  subject calpine daily gas nomination calpine d...  \n",
       "3  subject issue fyi see note already done stella...  \n",
       "4  subject meter nov allocation fyi forwarded lau...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56cdb08d-8771-4abf-bdd1-694750a12d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score , precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d42d597-33c0-415f-b85c-06dff2c51c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "Precision: 0.89\n",
      "Recall: 0.94\n",
      "F1-Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 3000)\n",
    "\n",
    "X = vectorizer.fit_transform(df['clean_content']).toarray()\n",
    "\n",
    "y = df['category'].apply(lambda x:1 if x == 'spam' else 0)\n",
    "\n",
    "X_train , X_test , y_train , y_test  = train_test_split(X, y ,test_size = 0.2,random_state=42)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(X_train , y_train)\n",
    "\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "precision = precision_score(y_test,y_pred)\n",
    "recall = recall_score(y_test , y_pred)\n",
    "f1 =f1_score(y_test,y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb044d-68b0-4740-883c-1c4b0ceb122c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
